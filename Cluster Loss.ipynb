{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae77a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "from pytorch_metric_learning.losses import BaseMetricLossFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f45eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deep_clustering_loss(BaseMetricLossFunction):\n",
    "    def compute_loss(self, embedding, tgt_index, binary_mask=None):\n",
    "\n",
    "        spk_cnt = len(tgt_index.unique())\n",
    "\n",
    "        batch, bins, frames = tgt_index.shape\n",
    "        if binary_mask is None:\n",
    "            binary_mask = torch.ones(batch, bins * frames, 1)\n",
    "        binary_mask = binary_mask.float()\n",
    "        if len(binary_mask.shape) == 3:\n",
    "            binary_mask = binary_mask.view(batch, bins * frames, 1)\n",
    "        # If boolean mask, make it float.\n",
    "        binary_mask = binary_mask.to(tgt_index.device)\n",
    "\n",
    "        # Fill in one-hot vector for each TF bin\n",
    "        tgt_embedding = torch.zeros(batch, bins * frames, spk_cnt, device=tgt_index.device)\n",
    "        tgt_embedding.scatter_(2, tgt_index.view(batch, bins * frames, 1), 1)\n",
    "\n",
    "        # Compute VAD-weighted DC loss\n",
    "        tgt_embedding = tgt_embedding * binary_mask\n",
    "        embedding = embedding * binary_mask\n",
    "        est_proj = torch.einsum(\"ijk,ijl->ikl\", embedding, embedding)\n",
    "        true_proj = torch.einsum(\"ijk,ijl->ikl\", tgt_embedding, tgt_embedding)\n",
    "        true_est_proj = torch.einsum(\"ijk,ijl->ikl\", embedding, tgt_embedding)\n",
    "        # Equation (1) in [1]\n",
    "        cost = batch_matrix_norm(est_proj) + batch_matrix_norm(true_proj)\n",
    "        cost = cost - 2 * batch_matrix_norm(true_est_proj)\n",
    "        # Divide by number of active bins, for each element in batch\n",
    "        return cost / torch.sum(binary_mask, dim=[1, 2])\n",
    "\n",
    "\n",
    "def batch_matrix_norm(matrix, norm_order=2):\n",
    "    keep_batch = list(range(1, matrix.ndim))\n",
    "    return torch.norm(matrix, p=norm_order, dim=keep_batch) ** norm_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a089eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss= deep_clustering_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b177102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
