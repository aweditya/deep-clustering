{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8dbf0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asteroid.data import LibriMix\n",
    "from asteroid_filterbanks import make_enc_dec\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from asteroid import torch_utils\n",
    "from asteroid_filterbanks.transforms import mag, apply_mag_mask\n",
    "from asteroid.dsp.vad import ebased_vad\n",
    "from asteroid.masknn.recurrent import SingleRNN\n",
    "from asteroid.utils.torch_utils import pad_x_to_y\n",
    "\n",
    "from pytorch_metric_learning.losses import BaseMetricLossFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2b8aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adopted from https://github.com/asteroid-team/asteroid/blob/master/asteroid/losses/cluster.py\n",
    "class deep_clustering_loss(BaseMetricLossFunction):\n",
    "    def compute_loss(self, embedding, tgt_index, binary_mask=None):\n",
    "        spk_cnt = len(tgt_index.unique())\n",
    "\n",
    "        batch, bins, frames = tgt_index.shape\n",
    "        if binary_mask is None:\n",
    "            binary_mask = torch.ones(batch, bins * frames, 1)\n",
    "        binary_mask = binary_mask.float()\n",
    "        if len(binary_mask.shape) == 3:\n",
    "            binary_mask = binary_mask.view(batch, bins * frames, 1)\n",
    "            \n",
    "        # If boolean mask, make it float.\n",
    "        binary_mask = binary_mask.to(tgt_index.device)\n",
    "\n",
    "        # Fill in one-hot vector for each TF bin\n",
    "        tgt_embedding = torch.zeros(batch, bins * frames, spk_cnt, device=tgt_index.device)\n",
    "        tgt_embedding.scatter_(2, tgt_index.view(batch, bins * frames, 1), 1)\n",
    "\n",
    "        # Compute VAD-weighted DC loss\n",
    "        tgt_embedding = tgt_embedding * binary_mask\n",
    "        embedding = embedding * binary_mask\n",
    "        est_proj = torch.einsum(\"ijk,ijl->ikl\", embedding, embedding)\n",
    "        true_proj = torch.einsum(\"ijk,ijl->ikl\", tgt_embedding, tgt_embedding)\n",
    "        true_est_proj = torch.einsum(\"ijk,ijl->ikl\", embedding, tgt_embedding)\n",
    "        \n",
    "        # Equation (1) in [1]\n",
    "        cost = batch_matrix_norm(est_proj) + batch_matrix_norm(true_proj)\n",
    "        cost = cost - 2 * batch_matrix_norm(true_est_proj)\n",
    "        \n",
    "        # Divide by number of active bins, for each element in batch\n",
    "        return cost / torch.sum(binary_mask, dim=[1, 2])\n",
    "\n",
    "def batch_matrix_norm(matrix, norm_order=2):\n",
    "    keep_batch = list(range(1, matrix.ndim))\n",
    "    return torch.norm(matrix, p=norm_order, dim=keep_batch) ** norm_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf31ccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the base Deep Clustering model without the Mask Inference head used in Chimera++\n",
    "# Adopted from https://github.com/asteroid-team/asteroid/blob/master/egs/wsj0-mix/DeepClustering/model.py\n",
    "\n",
    "def make_model(conf):\n",
    "    encoder, decoder = make_enc_dec('stft', **conf[\"filterbank\"])\n",
    "    embedding = Embedding(encoder.n_feats_out // 2, **conf[\"deepclustering\"])\n",
    "    model = Model(encoder, embedding, decoder)\n",
    "    return model\n",
    "\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        channel_in, \n",
    "        n_src=2, \n",
    "        rnn_type='lstm',\n",
    "        n_layers=2, \n",
    "        hidden_layer_size=600, \n",
    "        dropout=0.3,\n",
    "        embedding_dim=40, \n",
    "        take_log=True,\n",
    "        epsilon=1e-8\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channel_in = channel_in # channel_in = freq\n",
    "        self.n_src = n_src\n",
    "        self.take_log = take_log\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm = SingleRNN(\n",
    "            rnn_type, \n",
    "            channel_in, \n",
    "            hidden_layer_size, \n",
    "            n_layers=n_layers,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        lstm_output_dim = 2 * hidden_size\n",
    "        self.embedding_layer = nn.Linear(lstm_output_dim, channel_in * embedding_dim)\n",
    "        self.embedding_activation = nn.Tanh()\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, _, frames = input_data.shape\n",
    "        if self.take_log:\n",
    "            x = torch.log(x + self.epsilon)\n",
    "        \n",
    "        # LSTM layers\n",
    "        lstm_output = self.lstm(x.permute(0, 2, 1))\n",
    "        lstm_output = self.dropout(lstm_output)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        embedding_out = self.embedding_layer(lstm_output) # Shape is (batch_size, time, freq * embedding_size)\n",
    "        embedding_out = self.embedding_activation(embedding_out)\n",
    "        \n",
    "        # Make shape (batch_size, freq, time, embedding_size)\n",
    "        embedding_out = embedding_out.view(batch_size, frames, -1, self.embedding_dim)\n",
    "        embedding_out = embedding_out.transpose(1, 2)\n",
    "        \n",
    "        # Make shape (batch_size, freq * time, embedding_size)\n",
    "        embedding_out = embedding_out.reshape(batch_size, -1, self.embedding_dim)\n",
    "        \n",
    "        # Normalise (the embedding vector for each time * freq bin should be of unit norm)\n",
    "        embedding_norm = torch.norm(embedding_out, p=2, dim=-1, keepdim=True)\n",
    "        normalised_embedding = embedding_out / (embedding_norm + self.epsilon)\n",
    "        \n",
    "        return normalised_embedding\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, encoder, embedding, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.embedding = embedding\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "        tf_representation = self.encode(x)\n",
    "        spectral_magnitude = mag(tf_representation)\n",
    "        normalised_embedding = self.embedding(spectral_magnitude)\n",
    "        return normalised_embedding\n",
    "        \n",
    "    def cluster(self, x):\n",
    "        kmeans = KMeans(n_clusters=self.Embedding.n_src)\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "        tf_representation = self.encode(x)\n",
    "        spectral_magnitude = mag(tf_representation)\n",
    "        normalised_embedding = self.embedding(spectral_magnitude)\n",
    "    \n",
    "        # Ignore time-frequency with energy < -40dB\n",
    "        # ebased_vad = Energy based voice activity detection\n",
    "        retained_bins = ebased_vad(spectral_magnitude)\n",
    "        retained_embedding = normalised_embedding[retained_bins.view(1, -1)]\n",
    "        \n",
    "        clusters = kmeans.fit_predict(retained_embedding.cpu().data.numpy())\n",
    "        \n",
    "        # Create masks\n",
    "        est_masks = []\n",
    "        for i in range(self.Embedding.n_src):\n",
    "            mask = ~retained_bins\n",
    "            mask[retained_bins] = torch.from_numpy((clusters == i)).to(mask.device)\n",
    "            est_masks.append(mask.float())\n",
    "        \n",
    "        # Apply the mask\n",
    "        estimated_masks = torch.stack(est_masks, dim=1)\n",
    "        masked_representation = apply_mag_mask(tf_representation, estimated_masks)\n",
    "        # Pad masked audio to have same size as original\n",
    "        separated_wav = pad_x_to_y(self.decoder(masked), x)\n",
    "        return separated_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a54c6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
